{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Programs\\Anaconda\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from process_data import sample\n",
    "from basic_model import DeepModel_multi, gradients\n",
    "from visual_data import matplotlib_vision\n",
    "from matplotlib import ticker\n",
    "import time\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "class Net(DeepModel_multi):\n",
    "    def __init__(self, planes):\n",
    "        super(Net, self).__init__(planes, active=nn.GELU())\n",
    "        self.alpha_max, self.alpha_min = 2.5 * 10 ** 4, 0  # 2.5 / 10 ** 4\n",
    "        self.q = 0.1\n",
    "        self.GAMMA = 0.9\n",
    "\n",
    "    ########################强制边界的输出转换，L_b, ########################\n",
    "    def output_transform(self, inputs, outputs):\n",
    "        x, y = inputs[..., (0,)], inputs[..., (1,)]\n",
    "        bc = 16 * x * (1 - x) * y * (1 - y)# 在x=0, x=1, y=1, y=0上保证u=u0, v=0\n",
    "        # u\n",
    "        u0 = 1\n",
    "        u = torch.abs(u0 + bc * outputs[..., (0,)])\n",
    "        # v\n",
    "        v = bc * outputs[..., (1,)]\n",
    "        # p\n",
    "        p = (1 - x) * outputs[..., (2,)]# 在x=1上p=0\n",
    "        # rho\n",
    "        # rho = tf.math.exp(-bc * tf.math.square(outputs[:, 3:]))\n",
    "        # rho = 1 + bc * outputs[:, 3:]\n",
    "        center = torch.square(x - 0.5) + torch.square(y - 0.5)\n",
    "        # rho = center * outputs[:, 3:]\n",
    "        rho = center * (\n",
    "                bc * outputs[..., (3,)] + (1 - bc) * (1 + 1e-6 / 0.25) / (center + 1e-6)\n",
    "        )\n",
    "        rho = torch.maximum(torch.minimum(torch.ones_like(rho), rho), torch.zeros_like(rho))\n",
    "        return torch.cat((u, v, p, rho), dim=-1)\n",
    "\n",
    "    ########################方程参数： 质量力的alpha系数######################\n",
    "    def alpha(self, rho):\n",
    "        return self.alpha_max + (self.alpha_min - self.alpha_max) * rho * (1 + self.q) / (rho + self.q)\n",
    "\n",
    "    ########################动量和连续方程残差 F ############################\n",
    "    def equation(self, inn_var, out_var):\n",
    "        u, v, p, rho = out_var[:, (0,)], out_var[:, (1,)], out_var[:, (2,)], out_var[:, (3,)]\n",
    "        duda = gradients(u, inn_var)\n",
    "        dudx, dudy = duda[:, (0,)], duda[:, (1,)]\n",
    "        d2udx2 = gradients(dudx, inn_var)[:, (0,)]\n",
    "        d2udy2 = gradients(dudy, inn_var)[:, (1,)]\n",
    "\n",
    "        dvda = gradients(v, inn_var)\n",
    "        dvdx, dvdy = dvda[:, (0,)], dvda[:, (1,)]\n",
    "        d2vdx2 = gradients(dvdx, inn_var)[:, (0,)]\n",
    "        d2vdy2 = gradients(dvdy, inn_var)[:, (1,)]\n",
    "\n",
    "        dpda = gradients(p, inn_var)\n",
    "        dpdx, dpdy= dpda[:, (0,)], dpda[:, (1,)]\n",
    "\n",
    "        fx, fy = self.alpha(rho) * u, self.alpha(rho) * v\n",
    "        eq1 = (-(d2udx2 + d2udy2) + dpdx - fx) * 0.01\n",
    "        eq2 = (-(d2vdx2 + d2vdy2) + dpdy - fy) * 0.01\n",
    "        eq3 = (dudx + dvdy) * 100.\n",
    "\n",
    "        return torch.cat([eq1, eq2, eq3], dim=-1), duda, dvda\n",
    "\n",
    "    ######################## 不等式残差，h: 密度积分应该大于0.9 ###############\n",
    "    ## 该函数直接输出全域的一个积分值\n",
    "    def inequal_constrain(self, y):\n",
    "\n",
    "        return torch.square(torch.maximum(torch.tensor(0.0, dtype=torch.float32).to(device), torch.mean(y[:, -1]) - self.GAMMA))\n",
    "\n",
    "    ######################## 优化目标，J: 耗散功 ############################\n",
    "    ## if_reduced 输出全域的平均值 ，否则 各点耗散功\n",
    "    def optim_func(self, inn_var, out_var, duda, dvda, if_reduced=False):\n",
    "        p1 = torch.sum(torch.square(duda) + torch.square(dvda), dim=1)# keepdim, 保留缩减的维度为1\n",
    "        p2 = self.alpha(out_var[:, 3]) * torch.sum(torch.square(out_var[:, :2]), dim=1)\n",
    "        if if_reduced:\n",
    "            return torch.mean(0.5 * (p1 + p2))\n",
    "        else:\n",
    "            return 0.5 * (p1 + p2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Programs\\Anaconda\\lib\\site-packages\\skopt\\sampler\\sobol.py:250: UserWarning: The balance properties of Sobol' points require n to be a power of 2. 0 points have been previously generated, then: n=0+16386=16386. \n",
      "  total_n_samples))\n",
      "F:\\Programs\\Anaconda\\lib\\site-packages\\skopt\\sampler\\sobol.py:250: UserWarning: The balance properties of Sobol' points require n to be a power of 2. 0 points have been previously generated, then: n=0+130=130. \n",
      "  total_n_samples))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "res_path = 'hpinn_stokes\\\\'\n",
    "isCreated = os.path.exists(res_path)\n",
    "if not isCreated:\n",
    "    os.makedirs(res_path)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "def gen_dataset(bounds, N_sample, method=\"pseudo\", ndim=1):\n",
    "\n",
    "    if ndim == 0:\n",
    "        return bounds[0] * np.ones([N_sample, 1])\n",
    "    elif ndim == 1:\n",
    "        if method == 'uniform':\n",
    "            return np.linspace(bounds[0], bounds[1], N_sample)\n",
    "        else:\n",
    "            X = sample(N_sample, ndim, method)\n",
    "            return X * (np.array(bounds)[1]-np.array(bounds)[0]) + np.array(bounds)[0]\n",
    "    elif ndim == 2:\n",
    "        if method == 'uniform':\n",
    "            n = int(np.sqrt(N_sample))\n",
    "            x0 = np.linspace(bounds[0, 0], bounds[0, 1], n)\n",
    "            x1 = np.linspace(bounds[1, 0], bounds[1, 1], n)\n",
    "            X = np.concatenate([np.tile(x0, 1, n), np.tile(x1, 1, n)], axis=-1)\n",
    "            return np.reshape(X, [-1, 2])\n",
    "        else:\n",
    "            X = sample(N_sample, ndim, method)\n",
    "            return X * (np.array(bounds)[:, 1]-np.array(bounds)[:, 0]) + np.array(bounds)[:, 0]\n",
    "\n",
    "# x [-1, 1] t [0, 1]\n",
    "N_inner, N_bound = 64*64, 64\n",
    "bound_x, bound_y = [0, 1], [0, 1]\n",
    "x_inner = gen_dataset([bound_x, bound_y], N_inner, method='Sobol', ndim=2)\n",
    "X_bond11 = np.concatenate([np.ones([N_bound, 1]) * bound_x[0], gen_dataset(bound_y, N_bound, method='Sobol', ndim=1)], axis=1).astype(dtype=np.float32)\n",
    "X_bond12 = np.concatenate([np.ones([N_bound, 1]) * bound_x[1], gen_dataset(bound_y, N_bound, method='Sobol', ndim=1)], axis=1).astype(dtype=np.float32)\n",
    "X_bond21 = np.concatenate([gen_dataset(bound_x, N_bound, method='Sobol', ndim=1), np.ones([N_bound, 1]) * bound_y[0]], axis=1).astype(dtype=np.float32)\n",
    "X_bond22 = np.concatenate([gen_dataset(bound_x, N_bound, method='Sobol', ndim=1), np.ones([N_bound, 1]) * bound_y[1]], axis=1).astype(dtype=np.float32)\n",
    "\n",
    "input = np.concatenate([X_bond11, X_bond12, X_bond21, X_bond22, x_inner,], axis=0).astype(np.float32)\n",
    "field = np.zeros_like(input[:, (0, )]) # 未用到\n",
    "\n",
    "input_train = torch.tensor(input, dtype=torch.float32).to(device)\n",
    "field_train = torch.tensor(field, dtype=torch.float32).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train(inn_var, bounds, model, loss, weight, optimizer, scheduler, log_loss):\n",
    "\n",
    "    ind_bounds1 = torch.isclose(inn_var[:, 0], torch.ones_like(inn_var[:, 0]) * bounds[0][0])\n",
    "    ind_bounds2 = torch.isclose(inn_var[:, 0], torch.ones_like(inn_var[:, 0]) * bounds[0][1])\n",
    "    ind_bounds3 = torch.isclose(inn_var[:, 1], torch.ones_like(inn_var[:, 1]) * bounds[1][0])\n",
    "    ind_bounds4 = torch.isclose(inn_var[:, 1], torch.ones_like(inn_var[:, 1]) * bounds[1][1])\n",
    "\n",
    "    ind = torch.arange(inn_var.shape[0], dtype=torch.long).to(device)\n",
    "    ind_inner =ind[~ind_bounds1*~ind_bounds2*~ind_bounds3*~ind_bounds4]\n",
    "\n",
    "    # if not adaptive or len(log_loss) == 0:\n",
    "    #     weight = 1.0\n",
    "    # else:\n",
    "    #     weight = log_loss[-1][-2]\n",
    "\n",
    "    def closure():\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_var = model(inn_var)\n",
    "        out_var = model.output_transform(inn_var, out_var)\n",
    "        res_i, duda, dvda = model.equation(inn_var, out_var)\n",
    "        eqs_loss_1 = loss(res_i[:, 0], torch.zeros_like(res_i[:, 0], dtype=torch.float32))\n",
    "        eqs_loss_2 = loss(res_i[:, 1], torch.zeros_like(res_i[:, 1], dtype=torch.float32))\n",
    "        eqs_loss_3 = loss(res_i[:, 2], torch.zeros_like(res_i[:, 2], dtype=torch.float32))\n",
    "        # del res_i\n",
    "        ieq_loss = model.inequal_constrain(out_var[ind_inner])\n",
    "        opt = model.optim_func(inn_var[ind_inner], out_var[ind_inner], duda[ind_inner], dvda[ind_inner], if_reduced=True)\n",
    "        opt_loss = opt\n",
    "        loss_batch = weight[0] * eqs_loss_1 + weight[1] * eqs_loss_2 + weight[2] * eqs_loss_3\\\n",
    "                     + weight[3] * ieq_loss + weight[4] * opt_loss\n",
    "        loss_batch.backward()\n",
    "\n",
    "        log_loss.append([eqs_loss_1.item(), eqs_loss_2.item(), eqs_loss_3.item(),\n",
    "                         ieq_loss.item(), opt_loss.item(), loss_batch.item()])\n",
    "\n",
    "        return loss_batch\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def inference(inn_var, model):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_pred = model(inn_var)\n",
    "        out_pred = model.output_transform(inn_var, out_pred)\n",
    "        out_alph = model.alpha(out_pred[..., -1])\n",
    "\n",
    "    return out_pred, out_alph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 建立网络\n",
    "Net_model = Net(planes=[2] + [64]*4 + [4],).to(device)\n",
    "# 损失函数\n",
    "L2loss = nn.MSELoss()\n",
    "# 优化算法\n",
    "Optimizer = torch.optim.Adam(Net_model.parameters(), lr=0.001, betas=(0.7, 0.9))\n",
    "# 下降策略\n",
    "Scheduler = torch.optim.lr_scheduler.MultiStepLR(Optimizer, milestones=[30000], gamma=0.1)\n",
    "# 可视化\n",
    "Visual = matplotlib_vision('/')\n",
    "\n",
    "Boundary_epoch = [30001, ]\n",
    "display_epoch = 1000\n",
    "\n",
    "x_vis = np.linspace(0, 1, 81).astype(np.float32)[:, None]\n",
    "y_vis = np.linspace(0, 1, 81).astype(np.float32)[:, None]\n",
    "\n",
    "x_vis = np.tile(x_vis, (1, y_vis.shape[0]))  # Nx x Ny\n",
    "y_vis = np.tile(y_vis, (1, x_vis.shape[0])).T  # Nx x Ny\n",
    "input_visual = np.stack((x_vis, y_vis), axis=-1)\n",
    "input_visual = torch.tensor(input_visual, dtype=torch.float32, requires_grad=True).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iter:   1000, lr_net: 1.000e-03,  cost: 363.46 , total loss: 9.998e+01, eqs_loss_1: 7.474e-03, eqs_loss_2: 8.064e-06, eqs_loss_3: 9.399e-03, ieq_loss: 9.993e-03, opt_loss: 4.907e-02 \n",
      " iter:   2000, lr_net: 1.000e-03,  cost: 366.14 , total loss: 9.998e+01, eqs_loss_1: 5.830e-03, eqs_loss_2: 2.167e-04, eqs_loss_3: 3.685e-03, ieq_loss: 9.993e-03, opt_loss: 4.891e-02 \n",
      " iter:   3000, lr_net: 1.000e-03,  cost: 370.11 , total loss: 9.998e+01, eqs_loss_1: 3.913e-03, eqs_loss_2: 7.346e-04, eqs_loss_3: 4.264e-03, ieq_loss: 9.993e-03, opt_loss: 4.881e-02 \n",
      " iter:   4000, lr_net: 1.000e-03,  cost: 364.35 , total loss: 9.998e+01, eqs_loss_1: 2.760e-03, eqs_loss_2: 1.013e-03, eqs_loss_3: 1.259e-03, ieq_loss: 9.993e-03, opt_loss: 4.943e-02 \n",
      " iter:   5000, lr_net: 1.000e-03,  cost: 363.81 , total loss: 9.998e+01, eqs_loss_1: 2.345e-03, eqs_loss_2: 8.951e-04, eqs_loss_3: 6.355e-04, ieq_loss: 9.993e-03, opt_loss: 4.921e-02 \n",
      " iter:   6000, lr_net: 1.000e-03,  cost: 363.76 , total loss: 9.998e+01, eqs_loss_1: 2.102e-03, eqs_loss_2: 9.443e-04, eqs_loss_3: 5.941e-04, ieq_loss: 9.993e-03, opt_loss: 4.956e-02 \n",
      " iter:   7000, lr_net: 1.000e-03,  cost: 363.70 , total loss: 9.998e+01, eqs_loss_1: 2.749e-03, eqs_loss_2: 1.034e-03, eqs_loss_3: 5.009e-04, ieq_loss: 9.993e-03, opt_loss: 4.970e-02 \n",
      " iter:   8000, lr_net: 1.000e-03,  cost: 363.90 , total loss: 9.998e+01, eqs_loss_1: 2.096e-03, eqs_loss_2: 9.361e-04, eqs_loss_3: 7.613e-04, ieq_loss: 9.993e-03, opt_loss: 4.964e-02 \n",
      " iter:   9000, lr_net: 1.000e-03,  cost: 363.93 , total loss: 9.998e+01, eqs_loss_1: 1.822e-03, eqs_loss_2: 6.778e-04, eqs_loss_3: 1.782e-03, ieq_loss: 9.993e-03, opt_loss: 4.982e-02 \n",
      " iter:  10000, lr_net: 1.000e-03,  cost: 363.98 , total loss: 9.998e+01, eqs_loss_1: 2.184e-03, eqs_loss_2: 7.275e-04, eqs_loss_3: 2.191e-03, ieq_loss: 9.993e-03, opt_loss: 4.992e-02 \n",
      " iter:  11000, lr_net: 1.000e-03,  cost: 363.86 , total loss: 9.998e+01, eqs_loss_1: 1.403e-03, eqs_loss_2: 6.993e-04, eqs_loss_3: 3.449e-03, ieq_loss: 9.993e-03, opt_loss: 5.042e-02 \n",
      " iter:  12000, lr_net: 1.000e-03,  cost: 364.00 , total loss: 9.998e+01, eqs_loss_1: 6.829e-04, eqs_loss_2: 3.820e-04, eqs_loss_3: 1.194e-03, ieq_loss: 9.993e-03, opt_loss: 5.082e-02 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "star_time = time.time()\n",
    "log_loss = []\n",
    "pred_par = []\n",
    "mu_f, mu_h = 0.1/3, 1e4\n",
    "Weight = [mu_f, mu_f, mu_f, mu_h, 1.]\n",
    "\n",
    "inn_var = input_train\n",
    "inn_var.requires_grad_(True)\n",
    "# Training\n",
    "for iter in range(30001):\n",
    "\n",
    "    lr_net = Optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "    train(inn_var, [bound_x, bound_y], Net_model, L2loss, Weight, Optimizer, Scheduler, log_loss)\n",
    "\n",
    "    if iter > 0 and iter % display_epoch == 0:\n",
    "        print(' iter: {:6d}, lr_net: {:.3e},  cost: {:.2f} , total loss: {:.3e}, '\n",
    "              'eqs_loss_1: {:.3e}, eqs_loss_2: {:.3e}, eqs_loss_3: {:.3e}, ieq_loss: {:.3e}, opt_loss: {:.3e} '.\n",
    "              format(iter, lr_net,  time.time() - star_time, log_loss[-1][-1],\n",
    "                     log_loss[-1][0], log_loss[-1][1], log_loss[-1][2], log_loss[-1][3], log_loss[-1][4],))\n",
    "\n",
    "\n",
    "        plt.figure(1, figsize=(15, 10))\n",
    "        plt.clf()\n",
    "        Visual.plot_loss(np.arange(len(log_loss)), np.array(log_loss)[:, 0], 'eqs_loss_1')\n",
    "        Visual.plot_loss(np.arange(len(log_loss)), np.array(log_loss)[:, 1], 'eqs_loss_2')\n",
    "        Visual.plot_loss(np.arange(len(log_loss)), np.array(log_loss)[:, 2], 'eqs_loss_3')\n",
    "        Visual.plot_loss(np.arange(len(log_loss)), np.array(log_loss)[:, 3], 'ieq_loss')\n",
    "        Visual.plot_loss(np.arange(len(log_loss)), np.array(log_loss)[:, 4], 'opt_loss')\n",
    "        Visual.plot_loss(np.arange(len(log_loss)), np.array(log_loss)[:, -1], 'total_loss')\n",
    "        plt.savefig(res_path + 'log_loss.svg')\n",
    "\n",
    "        star_time = time.time()\n",
    "\n",
    "    if iter > 0 and iter % display_epoch == 0:\n",
    "\n",
    "        output_visual, alpha_visual = inference(input_visual, Net_model)\n",
    "        output_visual = output_visual.detach().cpu()\n",
    "\n",
    "        v_visual = torch.sqrt(output_visual[..., 0]**2 + output_visual[..., 1]**2)\n",
    "        field_visual = torch.stack((v_visual,output_visual[..., -2], output_visual[..., -1], alpha_visual.detach().cpu()), dim=-1).numpy()\n",
    "        coord_visual = input_visual.detach().cpu().numpy()\n",
    "        fmin, fmax = field_visual.min(axis=(0, 1)), field_visual.max(axis=(0, 1))\n",
    "        cmin, cmax = coord_visual.min(axis=(0, 1)), coord_visual.max(axis=(0, 1))\n",
    "        x_pos = coord_visual[:, :, 0]\n",
    "        y_pos = coord_visual[:, :, 1]\n",
    "        Num_fields = field_visual.shape[-1]\n",
    "\n",
    "\n",
    "        field_name = ['velocity', 'Pressure', 'rho', 'alpha']\n",
    "        input_name = ['x', 'y']\n",
    "        font = {'family': 'Times New Roman', 'weight': 'normal', 'size': 20}\n",
    "        for fi in range(Num_fields):\n",
    "            plt.figure(fi+1, figsize=(15, 10))\n",
    "            plt.clf()\n",
    "            plt.rcParams['font.size'] = 20\n",
    "            ########      Exact f(t,x,y)     ###########\n",
    "            # plt.subplot(1, Num_fields,  0 * Num_fields + fi + 1)\n",
    "            f_true = field_visual[:, :, fi]\n",
    "            plt.pcolormesh(x_pos, y_pos, f_true, cmap='RdBu_r', shading='gouraud', antialiased=True, snap=True)\n",
    "            cb = plt.colorbar()\n",
    "            plt.contour(x_pos, y_pos, f_true, levels=20, linestyles='-', linewidths=0.4, colors='k')\n",
    "            plt.axis((cmin[0], cmax[0], cmin[1], cmax[1]))\n",
    "            plt.clim(vmin=fmin[fi], vmax=fmax[fi])\n",
    "            cb.set_label('Analytical Solution $' + field_name[fi] + '$', rotation=0, fontdict=font, y=1.12)\n",
    "            # 设置图例字体和大小\n",
    "            cb.ax.tick_params(labelsize=20)\n",
    "            for l in cb.ax.yaxis.get_ticklabels():\n",
    "                l.set_family('Times New Roman')\n",
    "            tick_locator = ticker.MaxNLocator(nbins=5)  # colorbar上的刻度值个数\n",
    "            cb.locator = tick_locator\n",
    "            cb.update_ticks()\n",
    "            plt.xlabel('$' + input_name[0] + '$', fontdict=font)\n",
    "            plt.ylabel('$' + input_name[1] + '$', fontdict=font)\n",
    "            plt.yticks(fontproperties='Times New Roman', size=20)\n",
    "            plt.xticks(fontproperties='Times New Roman', size=20)\n",
    "            plt.savefig(res_path + 'field_' + str(field_name[fi]) + '-' + 'now.jpg')\n",
    "            # plt.savefig(res_path + 'field_' + str(field_name[fi]) + '-' + str(iter) + '.jpg')\n",
    "\n",
    "\n",
    "\n",
    "        torch.save({'epoch': iter, 'model': Net_model.state_dict(),\n",
    "                    'log_loss': np.array(log_loss)}, res_path + 'latest_model.pth')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}